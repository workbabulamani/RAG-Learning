{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78baa2ef",
   "metadata": {},
   "source": [
    "# Building a RAG system with OpenAI and ChromaDB\n",
    "\n",
    "#### Introduction\n",
    "Retrieval-Augmented Generation (RAG) is a powerful technique that combines the capabilities of large language models with external knowledge retrieval. This notebook will walk you through building a complete RAG system using:\n",
    "\n",
    "- LangChain: A framework for developing applications powered by language models\n",
    "- ChromaDB: An open-source vector database for storing and retrieving embeddings\n",
    "- OpenAI: For embeddings and language model (you can substitute with other providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fa1f310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Babu\\ragudemy\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# langchain imports\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    PyMuPDFLoader,\n",
    "    TextLoader\n",
    ")\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# vector stores\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Utilities\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63202d7",
   "metadata": {},
   "source": [
    "## RAG Architecture Overview\n",
    "### RAG (Retrieval-Augmented Generation) Architecture:\n",
    "\n",
    "1. Document Loading: Load documents from various sources\n",
    "2. Document Splitting: Break documents into smaller chunks\n",
    "3. Embedding Generation: Convert chunks into vector representations\n",
    "4. Vector Storage: Store embeddings in ChromaDB\n",
    "5. Query Processing: Convert user query to embedding\n",
    "6. Similarity Search: Find relevant chunks from vector store\n",
    "7. Context Augmentation: Combine retrieved chunks with query\n",
    "8. Response Generation: LLM generates answer using context\n",
    "\n",
    "Benefits of RAG:\n",
    "- Reduces hallucinations\n",
    "- Provides up-to-date information\n",
    "- Allows citing sources\n",
    "- Works with domain-specific knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eb244e",
   "metadata": {},
   "source": [
    "### Create sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffb4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Machine Learning Fundamentals\n",
    "    \n",
    "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
    "    and improve from experience without being explicitly programmed. There are three main \n",
    "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
    "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
    "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "    \n",
    "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
    "    These networks are inspired by the human brain and consist of layers of interconnected \n",
    "    nodes. Deep learning has revolutionized fields like computer vision, natural language \n",
    "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
    "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
    "    excel at sequential data processing.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Natural Language Processing (NLP)\n",
    "    \n",
    "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
    "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
    "    machine translation, and question answering. Modern NLP heavily relies on transformer \n",
    "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
    "    context and relationships between words in text.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01eb8af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document created: C:\\Users\\LSHIVA~1\\AppData\\Local\\Temp\\tmp9cr5i63a\n"
     ]
    }
   ],
   "source": [
    "# save to file\n",
    "import tempfile\n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "for i, doc in enumerate(sample_docs):\n",
    "    with open(f\"{temp_dir}/doc_{i}.txt\", \"w\") as f:\n",
    "        f.write(doc)\n",
    "\n",
    "print(f\"Sample document created: {temp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5926a",
   "metadata": {},
   "source": [
    "### Document loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b968fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a58a394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "\n",
      "First document preview: \n",
      "\n",
      "    Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. Ther...\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(\n",
    "    path=temp_dir,\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding':\"utf-8\"}\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"\\nFirst document preview: \")\n",
    "print(documents[0].page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f43c4b3",
   "metadata": {},
   "source": [
    "### Document splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee0e089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 7 chunks from 3 documents\n",
      "\n",
      "Chunk example:\n",
      "Content: Machine Learning Fundamentals...\n",
      "Metadata: {'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_0.txt'}\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50,\n",
    "    length_function = len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"] # heirarchy of separators\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents=documents)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "print(f\"\\nChunk example:\")\n",
    "print(f\"Content: {chunks[0].page_content[:150]}...\")\n",
    "print(f\"Metadata: {chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2f42ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_0.txt'}, page_content='interaction with an environment using rewards and penalties.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_1.txt'}, page_content='excel at sequential data processing.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd4bd1f",
   "metadata": {},
   "source": [
    "### Embeddings models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422052d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6141ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93757ed0",
   "metadata": {},
   "source": [
    "### Initialize chromadb vector store and store chunks in vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8463e327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 7 vectors\n",
      "Persisted to: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "# create chromadb vector store\n",
    "persist_dir = \"./chroma_db\"\n",
    "\n",
    "# initialize chromadb with openai embeddings\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=persist_dir,\n",
    "    collection_name=\"rag_collection\"\n",
    ")\n",
    "\n",
    "print(f\"Vector store created with {vectorstore._collection.count()} vectors\")\n",
    "print(f\"Persisted to: {persist_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8daa02c",
   "metadata": {},
   "source": [
    "### Test similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "140744f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the types of machine learning?\"\n",
    "\n",
    "similar_docs = vectorstore.similarity_search(query=query, k=3)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0020fba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the types of machine learning?\n",
      "\n",
      "Top 3 similar chunks: \n",
      "\n",
      "--- Chunk 1 ---\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine l...\n",
      "Source: C:\\Users\\LSHIVA~1\\AppData\\Local\\Temp\\tmp9cr5i63a\\doc_0.txt\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Machine Learning Fundamentals...\n",
      "Source: C:\\Users\\LSHIVA~1\\AppData\\Local\\Temp\\tmp9cr5i63a\\doc_0.txt\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Deep Learning and Neural Networks...\n",
      "Source: C:\\Users\\LSHIVA~1\\AppData\\Local\\Temp\\tmp9cr5i63a\\doc_1.txt\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: {query}\")\n",
    "print(f\"\\nTop {len(similar_docs)} similar chunks: \")\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(doc.page_content[:200]+\"...\")\n",
    "    print(f\"Source: {doc.metadata.get('source', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2485f",
   "metadata": {},
   "source": [
    "### Advanced similarity search with scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caefb8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  0.24275080859661102),\n",
       " (Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals'),\n",
       "  0.2676756680011749),\n",
       " (Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       "  0.29335978627204895)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vectorstore.similarity_search_with_score(query, k=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629fe213",
   "metadata": {},
   "source": [
    "#### Understanding Similarity Scores\n",
    "The similarity score represents how closely related a document chunk is to your query. The scoring depends on the distance metric used:\n",
    "\n",
    "ChromaDB default: Uses L2 distance (Euclidean distance)\n",
    "\n",
    "- Lower scores = MORE similar (closer in vector space)\n",
    "- Score of 0 = identical vectors\n",
    "- Typical range: 0 to 2 (but can be higher)\n",
    "\n",
    "\n",
    "Cosine similarity (if configured):\n",
    "\n",
    "- Higher scores = MORE similar\n",
    "- Range: -1 to 1 (1 being identical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed993f50",
   "metadata": {},
   "source": [
    "### Initialize the LLM (OpenAI), RAG chain, Prompt template, query the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71b775a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name = \"gpt-3.5-turbo\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c087a7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Large language models are a type of artificial intelligence model that is trained on vast amounts of text data to generate human-like text. These models are capable of understanding and generating natural language text, and can be used for a variety of tasks such as text generation, translation, summarization, and more. Large language models have become increasingly popular in recent years due to their ability to generate high-quality text and their potential applications in various fields such as natural language processing, machine translation, and conversational AI. Some well-known examples of large language models include GPT-3 (Generative Pre-trained Transformer 3) and BERT (Bidirectional Encoder Representations from Transformers).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 133, 'prompt_tokens': 13, 'total_tokens': 146, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CcXiRa8lWWa1vjRYE4SFTytWIWYNF', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--2f79661d-93a5-4d72-a284-d35c99d3c371-0', usage_metadata={'input_tokens': 13, 'output_tokens': 133, 'total_tokens': 146, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_response = llm.invoke(\"What is Large language models?\")\n",
    "test_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "946ac7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Large language models are a type of artificial intelligence designed to process and generate human-like language at scale. These models are built using deep learning techniques and trained on massive amounts of text data to understand and generate language. They can be used for a variety of natural language processing tasks such as text generation, translation, summarization, question answering, and more. Large language models have gained popularity in recent years due to their ability to produce high-quality and coherent text outputs. Examples of large language models include OpenAI's GPT-3 and Google's BERT.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 111, 'prompt_tokens': 13, 'total_tokens': 124, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CcXjwuzsClnR1gHRGsdIFFzBHOG8V', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--50649f88-4b30-4aed-824d-d4af691b50d0-0', usage_metadata={'input_tokens': 13, 'output_tokens': 111, 'total_tokens': 124, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models.base import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"openai:gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "# llm = init_chat_model(\n",
    "#     model=\"groq:\"\n",
    "# )\n",
    "\n",
    "test_response = llm.invoke(\"What is Large language models?\")\n",
    "test_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc412d4f",
   "metadata": {},
   "source": [
    "### Modern RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c25f9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c02aca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001DAF62DBA10>, search_kwargs={})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert vector store to retiever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwarg = {'k':3} ## Retrieve top 3 relevant chunks\n",
    ")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8614e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a prompt template\n",
    "system_prompt = \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrived context to answer the question.\n",
    "If you dont know the answer, just say that you dont know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt),\n",
    "     (\"human\", \"{input}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9a67893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'],\n",
       " 'kwargs': {'input_variables': ['context', 'input'],\n",
       "  'messages': [SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nYou are an assistant for question-answering tasks.\\nUse the following pieces of retrived context to answer the question.\\nIf you dont know the answer, just say that you dont know.\\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\\n'), additional_kwargs={}),\n",
       "   HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]},\n",
       " 'name': 'ChatPromptTemplate'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1a54eb",
   "metadata": {},
   "source": [
    "### Create document chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4eaac02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nYou are an assistant for question-answering tasks.\\nUse the following pieces of retrived context to answer the question.\\nIf you dont know the answer, just say that you dont know.\\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001DAFA690190>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001DAFA690410>, root_client=<openai.OpenAI object at 0x000001DAF6EB9A70>, root_async_client=<openai.AsyncOpenAI object at 0x000001DAF6EBAC40>, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c1b88",
   "metadata": {},
   "source": [
    "This chain:\n",
    "\n",
    "- Takes retrieved documents\n",
    "- \"Stuffs\" them into the prompt's {context} placeholder\n",
    "- Sends the complete prompt to the LLM\n",
    "- Returns the LLM's response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd29c12c",
   "metadata": {},
   "source": [
    "#### What is create_retrieval_chain?\n",
    "create_retrieval_chain is a function that combines a retriever (which fetches relevant documents) with a document chain (which processes those documents with an LLM) to create a complete RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48abbd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001DAF62DBA10>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nYou are an assistant for question-answering tasks.\\nUse the following pieces of retrived context to answer the question.\\nIf you dont know the answer, just say that you dont know.\\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001DAFA690190>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001DAFA690410>, root_client=<openai.OpenAI object at 0x000001DAF6EB9A70>, root_async_client=<openai.AsyncOpenAI object at 0x000001DAF6EBAC40>, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain = create_retrieval_chain(retriever, document_chain)\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3dff1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is machine learning?',\n",
       " 'context': [Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals'),\n",
       "  Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       "  Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers')],\n",
       " 'answer': 'Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. It includes supervised learning, unsupervised learning, and reinforcement learning as its main types. Supervised learning uses labeled data, unsupervised learning finds patterns in unlabeled data, and reinforcement learning learns through interaction with an environment.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is machine learning?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "884f3cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. It includes supervised learning, unsupervised learning, and reinforcement learning as its main types. Supervised learning uses labeled data, unsupervised learning finds patterns in unlabeled data, and reinforcement learning learns through interaction with an environment.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23d06d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the three types of machine learning?\n",
      "--------------------------------------------------\n",
      "Answer: The three main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data for training, while unsupervised learning searches for patterns in unlabeled data. Reinforcement learning learns through a system of trial and error.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      "--- Source 1 ---\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine l...\n",
      "\n",
      "--- Source 2 ---\n",
      "Machine Learning Fundamentals...\n",
      "\n",
      "--- Source 3 ---\n",
      "Deep Learning and Neural Networks...\n",
      "\n",
      "--- Source 4 ---\n",
      "Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question: What is deep learning and how does it relate to neural networks?\n",
      "--------------------------------------------------\n",
      "Answer: Deep learning is a subset of machine learning that is based on artificial neural networks inspired by the human brain. These networks consist of interconnected nodes organized in layers to process data and extract patterns. Deep learning has significantly advanced fields such as computer vision, natural language processing, and speech recognition.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      "--- Source 1 ---\n",
      "Deep Learning and Neural Networks...\n",
      "\n",
      "--- Source 2 ---\n",
      "Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning...\n",
      "\n",
      "--- Source 3 ---\n",
      "Machine Learning Fundamentals...\n",
      "\n",
      "--- Source 4 ---\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine l...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question: What are CNNs best used for?\n",
      "--------------------------------------------------\n",
      "Answer: CNNs are particularly effective for image processing due to their ability to automatically learn and extract features from visual data. They are commonly used in tasks such as image classification, object detection, and facial recognition. CNNs utilize layers of convolutional filters to capture spatial hierarchies in images, making them well-suited for tasks that involve recognizing patterns in visual data.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      "--- Source 1 ---\n",
      "Deep Learning and Neural Networks...\n",
      "\n",
      "--- Source 2 ---\n",
      "Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning...\n",
      "\n",
      "--- Source 3 ---\n",
      "Machine Learning Fundamentals...\n",
      "\n",
      "--- Source 4 ---\n",
      "Natural Language Processing (NLP)\n",
      "\n",
      "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
      "    Key tasks in NLP include text classification, named entity recogn...\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to query the modern RAG system\n",
    "def query_rag_modern(question):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Using create_retrieval_chain approach\n",
    "    result = rag_chain.invoke({\"input\": question})\n",
    "    \n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    print(\"\\nRetrieved Context:\")\n",
    "    for i, doc in enumerate(result['context']):\n",
    "        print(f\"\\n--- Source {i+1} ---\")\n",
    "        print(doc.page_content[:200] + \"...\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test queries\n",
    "test_questions = [\n",
    "    \"What are the three types of machine learning?\",\n",
    "    \"What is deep learning and how does it relate to neural networks?\",\n",
    "    \"What are CNNs best used for?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    result = query_rag_modern(question)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f79e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragudemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
