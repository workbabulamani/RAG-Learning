{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78baa2ef",
   "metadata": {},
   "source": [
    "# Building a RAG system with OpenAI and ChromaDB\n",
    "\n",
    "#### Introduction\n",
    "Retrieval-Augmented Generation (RAG) is a powerful technique that combines the capabilities of large language models with external knowledge retrieval. This notebook will walk you through building a complete RAG system using:\n",
    "\n",
    "- LangChain: A framework for developing applications powered by language models\n",
    "- ChromaDB: An open-source vector database for storing and retrieving embeddings\n",
    "- OpenAI: For embeddings and language model (you can substitute with other providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fa1f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# langchain imports\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    PyMuPDFLoader,\n",
    "    TextLoader\n",
    ")\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# vector stores\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Utilities\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63202d7",
   "metadata": {},
   "source": [
    "## RAG Architecture Overview\n",
    "### RAG (Retrieval-Augmented Generation) Architecture:\n",
    "\n",
    "1. Document Loading: Load documents from various sources\n",
    "2. Document Splitting: Break documents into smaller chunks\n",
    "3. Embedding Generation: Convert chunks into vector representations\n",
    "4. Vector Storage: Store embeddings in ChromaDB\n",
    "5. Query Processing: Convert user query to embedding\n",
    "6. Similarity Search: Find relevant chunks from vector store\n",
    "7. Context Augmentation: Combine retrieved chunks with query\n",
    "8. Response Generation: LLM generates answer using context\n",
    "\n",
    "Benefits of RAG:\n",
    "- Reduces hallucinations\n",
    "- Provides up-to-date information\n",
    "- Allows citing sources\n",
    "- Works with domain-specific knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eb244e",
   "metadata": {},
   "source": [
    "### Create sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ffb4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Machine Learning Fundamentals\n",
    "    \n",
    "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
    "    and improve from experience without being explicitly programmed. There are three main \n",
    "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
    "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
    "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "    \n",
    "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
    "    These networks are inspired by the human brain and consist of layers of interconnected \n",
    "    nodes. Deep learning has revolutionized fields like computer vision, natural language \n",
    "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
    "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
    "    excel at sequential data processing.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Natural Language Processing (NLP)\n",
    "    \n",
    "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
    "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
    "    machine translation, and question answering. Modern NLP heavily relies on transformer \n",
    "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
    "    context and relationships between words in text.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01eb8af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document created: C:\\Users\\LSHIVA~1\\AppData\\Local\\Temp\\tmplfq91iub\n"
     ]
    }
   ],
   "source": [
    "# save to file\n",
    "import tempfile\n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "for i, doc in enumerate(sample_docs):\n",
    "    with open(f\"{temp_dir}/doc_{i}.txt\", \"w\") as f:\n",
    "        f.write(doc)\n",
    "\n",
    "print(f\"Sample document created: {temp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5926a",
   "metadata": {},
   "source": [
    "### Document loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b968fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a58a394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "\n",
      "First document preview: \n",
      "\n",
      "    Machine Learning Fundamentals\n",
      "    \n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. ...\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(\n",
    "    path=temp_dir,\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding':\"utf-8\"}\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"\\nFirst document preview: \")\n",
    "print(documents[0].page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f43c4b3",
   "metadata": {},
   "source": [
    "### Document splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee0e089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 chunks from 3 documents\n",
      "\n",
      "Chunk example:\n",
      "Content: Machine Learning Fundamentals\n",
      "    \n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from exp...\n",
      "Metadata: {'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmplfq91iub\\\\doc_0.txt'}\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50,\n",
    "    length_function = len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"] # heirarchy of separators\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents=documents)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "print(f\"\\nChunk example:\")\n",
    "print(f\"Content: {chunks[0].page_content[:150]}...\")\n",
    "print(f\"Metadata: {chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f2f42ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmplfq91iub\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n    \\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmplfq91iub\\\\doc_0.txt'}, page_content='interaction with an environment using rewards and penalties.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmplfq91iub\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n    \\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmplfq91iub\\\\doc_1.txt'}, page_content='effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmplfq91iub\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n    \\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd4bd1f",
   "metadata": {},
   "source": [
    "### Embeddings models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "422052d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6141ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93757ed0",
   "metadata": {},
   "source": [
    "### Initialize chromadb vector store and store chunks in vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8463e327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 17 vectors\n",
      "Persisted to: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "# create chromadb vector store\n",
    "persist_dir = \"./chroma_db\"\n",
    "\n",
    "# initialize chromadb with openai embeddings\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=persist_dir,\n",
    "    collection_name=\"rag_collection\"\n",
    ")\n",
    "\n",
    "print(f\"Vector store created with {vectorstore._collection.count()} vectors\")\n",
    "print(f\"Persisted to: {persist_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8daa02c",
   "metadata": {},
   "source": [
    "### Test similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "140744f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpx6ltr9sk\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n    \\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmplfq91iub\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n    \\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the types of machine learning?\"\n",
    "\n",
    "similar_docs = vectorstore.similarity_search(query=query, k=3)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0020fba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the types of machine learning?\n",
      "\n",
      "Top 3 similar chunks: \n",
      "\n",
      "--- Chunk 1 ---\n",
      "Machine Learning Fundamentals\n",
      "    \n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There...\n",
      "Source: C:\\Users\\LSHIVA~1\\AppData\\Local\\Temp\\tmpx6ltr9sk\\doc_0.txt\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Machine Learning Fundamentals\n",
      "    \n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There...\n",
      "Source: C:\\Users\\LSHIVA~1\\AppData\\Local\\Temp\\tmplfq91iub\\doc_0.txt\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine l...\n",
      "Source: C:\\Users\\LSHIVA~1\\AppData\\Local\\Temp\\tmp9cr5i63a\\doc_0.txt\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: {query}\")\n",
    "print(f\"\\nTop {len(similar_docs)} similar chunks: \")\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(doc.page_content[:200]+\"...\")\n",
    "    print(f\"Source: {doc.metadata.get('source', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2485f",
   "metadata": {},
   "source": [
    "### Advanced similarity search with scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "caefb8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpx6ltr9sk\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n    \\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  0.24102914333343506),\n",
       " (Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmplfq91iub\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n    \\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  0.24120774865150452),\n",
       " (Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  0.2427261918783188)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vectorstore.similarity_search_with_score(query, k=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629fe213",
   "metadata": {},
   "source": [
    "#### Understanding Similarity Scores\n",
    "The similarity score represents how closely related a document chunk is to your query. The scoring depends on the distance metric used:\n",
    "\n",
    "ChromaDB default: Uses L2 distance (Euclidean distance)\n",
    "\n",
    "- Lower scores = MORE similar (closer in vector space)\n",
    "- Score of 0 = identical vectors\n",
    "- Typical range: 0 to 2 (but can be higher)\n",
    "\n",
    "\n",
    "Cosine similarity (if configured):\n",
    "\n",
    "- Higher scores = MORE similar\n",
    "- Range: -1 to 1 (1 being identical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed993f50",
   "metadata": {},
   "source": [
    "### Initialize the LLM (OpenAI), RAG chain, Prompt template, query the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71b775a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name = \"gpt-3.5-turbo\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c087a7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Large language models are a type of artificial intelligence model that are trained on vast amounts of text data in order to generate human-like text. These models are capable of understanding and generating natural language text, and are used in a variety of applications such as language translation, text generation, and natural language processing tasks. Some examples of large language models include GPT-3 (Generative Pre-trained Transformer 3) and BERT (Bidirectional Encoder Representations from Transformers).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 13, 'total_tokens': 106, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Ce3aqVYBcACPlGRJu4CzYtoA8atRl', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--d3184ace-95ad-4d07-b7e3-aa40c46c2273-0', usage_metadata={'input_tokens': 13, 'output_tokens': 93, 'total_tokens': 106, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_response = llm.invoke(\"What is Large language models?\")\n",
    "test_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "946ac7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Large language models are artificial intelligence algorithms that are trained on massive amounts of text data to understand and generate human language. These models have the ability to process and generate human-like text, often indistinguishable from text written by humans. Some well-known examples of large language models include GPT-3 (Generative Pre-trained Transformer 3) and BERT (Bidirectional Encoder Representations from Transformers). These models have a wide range of applications, such as natural language processing, machine translation, and text generation.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 13, 'total_tokens': 115, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Ce3ascdPtu2gSDHVE8dDwuo1hFzSj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--e2e41677-ddf4-4089-a3b7-4085fadf52da-0', usage_metadata={'input_tokens': 13, 'output_tokens': 102, 'total_tokens': 115, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models.base import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"openai:gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "# llm = init_chat_model(\n",
    "#     model=\"groq:\"\n",
    "# )\n",
    "\n",
    "test_response = llm.invoke(\"What is Large language models?\")\n",
    "test_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc412d4f",
   "metadata": {},
   "source": [
    "### Modern RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c25f9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c02aca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000019ADCC11C30>, search_kwargs={})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert vector store to retiever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwarg = {'k':3} ## Retrieve top 3 relevant chunks\n",
    ")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8614e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a prompt template\n",
    "system_prompt = \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrived context to answer the question.\n",
    "If you dont know the answer, just say that you dont know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt),\n",
    "     (\"human\", \"{input}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9a67893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'],\n",
       " 'kwargs': {'input_variables': ['context', 'input'],\n",
       "  'messages': [SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nYou are an assistant for question-answering tasks.\\nUse the following pieces of retrived context to answer the question.\\nIf you dont know the answer, just say that you dont know.\\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\\n'), additional_kwargs={}),\n",
       "   HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]},\n",
       " 'name': 'ChatPromptTemplate'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1a54eb",
   "metadata": {},
   "source": [
    "### Create document chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4eaac02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nYou are an assistant for question-answering tasks.\\nUse the following pieces of retrived context to answer the question.\\nIf you dont know the answer, just say that you dont know.\\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000019ADD6AE290>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000019ADD6AEA70>, root_client=<openai.OpenAI object at 0x0000019ADD6AEBF0>, root_async_client=<openai.AsyncOpenAI object at 0x0000019ADD6AE320>, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c1b88",
   "metadata": {},
   "source": [
    "This chain:\n",
    "\n",
    "- Takes retrieved documents\n",
    "- \"Stuffs\" them into the prompt's {context} placeholder\n",
    "- Sends the complete prompt to the LLM\n",
    "- Returns the LLM's response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd29c12c",
   "metadata": {},
   "source": [
    "#### What is create_retrieval_chain?\n",
    "create_retrieval_chain is a function that combines a retriever (which fetches relevant documents) with a document chain (which processes those documents with an LLM) to create a complete RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48abbd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000019ADCC11C30>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nYou are an assistant for question-answering tasks.\\nUse the following pieces of retrived context to answer the question.\\nIf you dont know the answer, just say that you dont know.\\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000019ADD6AE290>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000019ADD6AEA70>, root_client=<openai.OpenAI object at 0x0000019ADD6AEBF0>, root_async_client=<openai.AsyncOpenAI object at 0x0000019ADD6AE320>, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain = create_retrieval_chain(retriever, document_chain)\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3dff1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is machine learning?',\n",
       " 'context': [Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals'),\n",
       "  Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpx6ltr9sk\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n    \\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmplfq91iub\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n    \\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through')],\n",
       " 'answer': 'Machine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without explicit programming. It involves three main types: supervised learning, unsupervised learning, and reinforcement learning, each serving different purposes in data analysis and pattern recognition. Supervised learning uses labeled data, unsupervised learning finds patterns in unlabeled data, and reinforcement learning learns through a trial-and-error process.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is machine learning?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "884f3cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without explicit programming. It involves three main types: supervised learning, unsupervised learning, and reinforcement learning, each serving different purposes in data analysis and pattern recognition. Supervised learning uses labeled data, unsupervised learning finds patterns in unlabeled data, and reinforcement learning learns through a trial-and-error process.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23d06d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the three types of machine learning?\n",
      "--------------------------------------------------\n",
      "Answer: The three types of machine learning are supervised learning, unsupervised learning, and reinforcement learning.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      "--- Source 1 ---\n",
      "Machine Learning Fundamentals\n",
      "    \n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There...\n",
      "\n",
      "--- Source 2 ---\n",
      "Machine Learning Fundamentals\n",
      "    \n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There...\n",
      "\n",
      "--- Source 3 ---\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine l...\n",
      "\n",
      "--- Source 4 ---\n",
      "Machine Learning Fundamentals...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question: What is deep learning and how does it relate to neural networks?\n",
      "--------------------------------------------------\n",
      "Answer: Deep learning is a subset of machine learning that relies on artificial neural networks. These networks, inspired by the human brain, are composed of interconnected nodes. Deep learning has significantly advanced fields like computer vision and natural language processing through the use of neural networks.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      "--- Source 1 ---\n",
      "Deep Learning and Neural Networks...\n",
      "\n",
      "--- Source 2 ---\n",
      "Deep Learning and Neural Networks\n",
      "    \n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers ...\n",
      "\n",
      "--- Source 3 ---\n",
      "Deep Learning and Neural Networks\n",
      "    \n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers ...\n",
      "\n",
      "--- Source 4 ---\n",
      "Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Question: What are CNNs best used for?\n",
      "--------------------------------------------------\n",
      "Answer: CNNs are best used for image processing tasks due to their ability to effectively capture spatial hierarchies in data. They are commonly used in applications such as image recognition, object detection, and image segmentation. CNNs have revolutionized fields like computer vision by achieving state-of-the-art results in tasks such as image classification.\n",
      "\n",
      "Retrieved Context:\n",
      "\n",
      "--- Source 1 ---\n",
      "Deep Learning and Neural Networks...\n",
      "\n",
      "--- Source 2 ---\n",
      "Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning...\n",
      "\n",
      "--- Source 3 ---\n",
      "effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
      "    excel at sequential data processing....\n",
      "\n",
      "--- Source 4 ---\n",
      "effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
      "    excel at sequential data processing....\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to query the modern RAG system\n",
    "def query_rag_modern(question):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Using create_retrieval_chain approach\n",
    "    result = rag_chain.invoke({\"input\": question})\n",
    "    \n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    print(\"\\nRetrieved Context:\")\n",
    "    for i, doc in enumerate(result['context']):\n",
    "        print(f\"\\n--- Source {i+1} ---\")\n",
    "        print(doc.page_content[:200] + \"...\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test queries\n",
    "test_questions = [\n",
    "    \"What are the three types of machine learning?\",\n",
    "    \"What is deep learning and how does it relate to neural networks?\",\n",
    "    \"What are CNNs best used for?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    result = query_rag_modern(question)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da392e2",
   "metadata": {},
   "source": [
    "# Create RAG chain alternative: LCEL (LangChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d3f79e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even a more flexible approach using LECL\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b632b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom prompt\n",
    "custom_prompt = ChatPromptTemplate.from_template(\"\"\"Use the following context to answer the question.\n",
    "                                                 If you dont know the answer based on the context, say you don't know.\n",
    "                                                 Provide specific details from the context to support your answer.\n",
    "                                                 \n",
    "                                                 Context:\n",
    "                                                 {context}\n",
    "\n",
    "                                                 Question: {question}\n",
    "                                                 \n",
    "                                                 Answer:\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2249bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the output documents for the prompt\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6515e34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000019ADCC11C30>, search_kwargs={})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following context to answer the question.\\n                                                 If you dont know the answer based on the context, say you don't know.\\n                                                 Provide specific details from the context to support your answer.\\n                                                 \\n                                                 Context:\\n                                                 {context}\\n\\n                                                 Question: {question}\\n                                                 \\n                                                 Answer:\"), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000019ADD6AE290>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000019ADD6AEA70>, root_client=<openai.OpenAI object at 0x0000019ADD6AEBF0>, root_async_client=<openai.AsyncOpenAI object at 0x0000019ADD6AE320>, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build chain using LCEL\n",
    "rag_chain_lcel = (\n",
    "    {\n",
    "        'context': retriever| format_docs,\n",
    "        'question': RunnablePassthrough()\n",
    "    }\n",
    "     | custom_prompt\n",
    "     | llm\n",
    "     | StrOutputParser()\n",
    ")\n",
    "rag_chain_lcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6558a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning is a subset of machine learning based on artificial neural networks. These networks consist of layers of interconnected nodes and are inspired by the human brain. Deep learning has revolutionized fields like computer vision, natural language processing, and speech recognition.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_lcel.invoke(\"What the hell is deep learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0ff4231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmp9cr5i63a\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpx6ltr9sk\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n    \\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\LSHIVA~1\\\\AppData\\\\Local\\\\Temp\\\\tmplfq91iub\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n    \\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is deep learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "119e5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag_lcel(question):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    # method 1: pass string directly (when using RunnablePassThrough)\n",
    "    answer = rag_chain_lcel.invoke(question)\n",
    "    print(f\"Answer: {answer}\")\n",
    "\n",
    "    # get source documents seperately if needed\n",
    "    docs = retriever.invoke(question)\n",
    "    print(\"\\nSOurce Documents: \")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"\\n--- Source {i+1} ---\")\n",
    "        print(doc.page_content[:200]+\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d887c188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: whats all this about?\n",
      "--------------------------------------------------\n",
      "Answer: The context is discussing machine learning and deep learning fundamentals, specifically mentioning interaction with an environment using rewards and penalties. This is referring to reinforcement learning, a type of machine learning where an algorithm learns to perform a task through trial and error by receiving rewards for successful actions and penalties for unsuccessful actions.\n",
      "\n",
      "SOurce Documents: \n",
      "\n",
      "--- Source 1 ---\n",
      "Deep Learning and Neural Networks...\n",
      "\n",
      "--- Source 2 ---\n",
      "Machine Learning Fundamentals...\n",
      "\n",
      "--- Source 3 ---\n",
      "interaction with an environment using rewards and penalties....\n",
      "\n",
      "--- Source 4 ---\n",
      "interaction with an environment using rewards and penalties....\n"
     ]
    }
   ],
   "source": [
    "# Test LCEL chain\n",
    "query_rag_lcel(\"whats all this about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b75ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71e9ecc9",
   "metadata": {},
   "source": [
    "# Add New Documents to existing Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f9ec1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_document = \"\"\"\n",
    "Reinforcement Learning in Detail\n",
    "\n",
    "Reinforcement learning (RL) is a type of machine learning where an agent learns to make\n",
    "decisions by interacting with an environment. The agnet receives rewards or penalties\n",
    "based on its actions and learns to maximize cumulative rewards over time. Key concepts\n",
    "in RL include: states, actions, rewards, policies, and value functions. Popular RL \n",
    "algorithms include Q-learning, Deep Q-Networks (DQN), Policy gradient methods, and\n",
    "actor-critic methods. RL has been sucessfully applied to game playing (like AlphaGo),\n",
    "robotics, and autonomous systems.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "526d59e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement learning'}, page_content='\\nReinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make\\ndecisions by interacting with an environment. The agnet receives rewards or penalties\\nbased on its actions and learns to maximize cumulative rewards over time. Key concepts\\nin RL include: states, actions, rewards, policies, and value functions. Popular RL \\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy gradient methods, and\\nactor-critic methods. RL has been sucessfully applied to game playing (like AlphaGo),\\nrobotics, and autonomous systems.\\n')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc = Document(\n",
    "    page_content=new_document,\n",
    "    metadata={\n",
    "        \"source\":\"manual_addition\",\n",
    "        \"topic\":\"reinforcement learning\"\n",
    "    }\n",
    ")\n",
    "new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6197763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement learning'}, page_content='Reinforcement Learning in Detail'),\n",
       " Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement learning'}, page_content='Reinforcement learning (RL) is a type of machine learning where an agent learns to make\\ndecisions by interacting with an environment. The agnet receives rewards or penalties\\nbased on its actions and learns to maximize cumulative rewards over time. Key concepts\\nin RL include: states, actions, rewards, policies, and value functions. Popular RL \\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy gradient methods, and'),\n",
       " Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement learning'}, page_content='actor-critic methods. RL has been sucessfully applied to game playing (like AlphaGo),\\nrobotics, and autonomous systems.')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chunks = text_splitter.split_documents([new_doc])\n",
    "new_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c63418c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a2726eab-d2bd-4a8f-b895-d4805aa4083e',\n",
       " '1be427a5-5cb2-480c-ab06-bca06f4ce00f',\n",
       " '5bbea8f1-6ed1-4e7e-9c43-4b70d79dd453']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add new documents to vector store\n",
    "vectorstore.add_documents(new_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69ef6b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28933a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what are key concepts in reinforcement learning\n",
      "--------------------------------------------------\n",
      "Answer: Key concepts in reinforcement learning include states, actions, rewards, policies, and value functions.\n",
      "\n",
      "SOurce Documents: \n",
      "\n",
      "--- Source 1 ---\n",
      "Reinforcement Learning in Detail...\n",
      "\n",
      "--- Source 2 ---\n",
      "Reinforcement learning (RL) is a type of machine learning where an agent learns to make\n",
      "decisions by interacting with an environment. The agnet receives rewards or penalties\n",
      "based on its actions and l...\n",
      "\n",
      "--- Source 3 ---\n",
      "actor-critic methods. RL has been sucessfully applied to game playing (like AlphaGo),\n",
      "robotics, and autonomous systems....\n",
      "\n",
      "--- Source 4 ---\n",
      "Machine Learning Fundamentals...\n"
     ]
    }
   ],
   "source": [
    "new_question = \"what are key concepts in reinforcement learning\"\n",
    "query_rag_lcel(new_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03257fec",
   "metadata": {},
   "source": [
    "# Advanced RAG Techniques: Conversational Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "825e1476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a9007f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prompt that includes the chat history\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question\n",
    "which might reference context in the chat history, formulate a standalone question\n",
    "which can be understood without the chat history. DO not answer the question,\n",
    "just reformulate it if needed and otherwise return as it is.\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', contextualize_q_system_prompt),\n",
    "    MessagesPlaceholder(\"Chat_history\"),\n",
    "    ('human', \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e47f7d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000019ADCC11C30>, search_kwargs={}))], default=ChatPromptTemplate(input_variables=['Chat_history', 'input'], input_types={'Chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000019AEBE537F0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Given a chat history and the latest user question\\nwhich might reference context in the chat history, formulate a standalone question\\nwhich can be understood without the chat history. DO not answer the question,\\njust reformulate it if needed and otherwise return as it is.'), additional_kwargs={}), MessagesPlaceholder(variable_name='Chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000019ADD6AE290>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000019ADD6AEA70>, root_client=<openai.OpenAI object at 0x0000019ADD6AEBF0>, root_async_client=<openai.AsyncOpenAI object at 0x0000019ADD6AE320>, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000019ADCC11C30>, search_kwargs={})), kwargs={}, config={'run_name': 'chat_retriever_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_aware_retiever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "history_aware_retiever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d14cd5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you dont know the answer, just say that you dont know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", qa_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2102bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_rag_chain = create_retrieval_chain(\n",
    "    history_aware_retiever,\n",
    "    question_answer_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18977da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is machine learning?\n",
      "A: Machine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without being explicitly programmed. There are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data, unsupervised learning finds patterns in unlabeled data, and reinforcement learning learns through a trial-and-error process.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "result1 = conversational_rag_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"What is machine learning?\"}\n",
    ")\n",
    "\n",
    "print(f\"Q: What is machine learning?\")\n",
    "print(f\"A: {result1['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7da48dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is machine learning?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Machine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without being explicitly programmed. There are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data, unsupervised learning finds patterns in unlabeled data, and reinforcement learning learns through a trial-and-error process.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is machine learning?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Machine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without being explicitly programmed. There are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data, unsupervised learning finds patterns in unlabeled data, and reinforcement learning learns through a trial-and-error process.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.extend([HumanMessage(content=\"What is machine learning?\"),\n",
    "                     AIMessage(content=result1['answer'])])\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d488bff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'Chat_history'}.  Expected: ['Chat_history', 'input'] Received: ['chat_history', 'input']\\nNote: if you intended {Chat_history} to be part of the string and not a variable, please escape it with double curly braces like: '{{Chat_history}}'.\\nFor troubleshooting, visit: https://docs.langchain.com/oss/python/langchain/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result2 \u001b[38;5;241m=\u001b[39m \u001b[43mconversational_rag_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat_history\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5534\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5527\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5529\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5532\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5533\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5535\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5536\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5537\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5538\u001b[0m     )\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3127\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3125\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   3126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3127\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3128\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3129\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config)\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\runnables\\passthrough.py:507\u001b[0m, in \u001b[0;36mRunnableAssign.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    506\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:2050\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   2046\u001b[0m     child_config \u001b[38;5;241m=\u001b[39m patch_config(config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child())\n\u001b[0;32m   2047\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   2048\u001b[0m         output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   2049\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2050\u001b[0m             context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   2051\u001b[0m                 call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   2052\u001b[0m                 func,\n\u001b[0;32m   2053\u001b[0m                 input_,\n\u001b[0;32m   2054\u001b[0m                 config,\n\u001b[0;32m   2055\u001b[0m                 run_manager,\n\u001b[0;32m   2056\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2057\u001b[0m             ),\n\u001b[0;32m   2058\u001b[0m         )\n\u001b[0;32m   2059\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2060\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    427\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\runnables\\passthrough.py:493\u001b[0m, in \u001b[0;36mRunnableAssign._invoke\u001b[1;34m(self, value, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)  \u001b[38;5;66;03m# noqa: TRY004\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvalue,\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapper\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    494\u001b[0m         value,\n\u001b[0;32m    495\u001b[0m         patch_config(config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child()),\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    497\u001b[0m     ),\n\u001b[0;32m    498\u001b[0m }\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3853\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3848\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3849\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3850\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[0;32m   3851\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   3852\u001b[0m         ]\n\u001b[1;32m-> 3853\u001b[0m         output \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3854\u001b[0m             key: future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m   3855\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3856\u001b[0m         }\n\u001b[0;32m   3857\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3858\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3854\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3848\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3849\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3850\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[0;32m   3851\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   3852\u001b[0m         ]\n\u001b[0;32m   3853\u001b[0m         output \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m-> 3854\u001b[0m             key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3855\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3856\u001b[0m         }\n\u001b[0;32m   3857\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3858\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.10.12-windows-x86_64-none\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.10.12-windows-x86_64-none\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\uv\\python\\cpython-3.10.12-windows-x86_64-none\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3837\u001b[0m, in \u001b[0;36mRunnableParallel.invoke.<locals>._invoke_step\u001b[1;34m(step, input_, config, key)\u001b[0m\n\u001b[0;32m   3831\u001b[0m child_config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m   3832\u001b[0m     config,\n\u001b[0;32m   3833\u001b[0m     \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[0;32m   3834\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   3835\u001b[0m )\n\u001b[0;32m   3836\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m-> 3837\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3839\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3841\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5534\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5527\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5529\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5532\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5533\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5535\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5536\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5537\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5538\u001b[0m     )\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\runnables\\branch.py:234\u001b[0m, in \u001b[0;36mRunnableBranch.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    236\u001b[0m             config\u001b[38;5;241m=\u001b[39mpatch_config(\n\u001b[0;32m    237\u001b[0m                 config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbranch:default\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    238\u001b[0m             ),\n\u001b[0;32m    239\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    240\u001b[0m         )\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    242\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3127\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3125\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   3126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3127\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3128\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3129\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config)\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\prompts\\base.py:217\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[0;32m    216\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m--> 217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:2050\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   2046\u001b[0m     child_config \u001b[38;5;241m=\u001b[39m patch_config(config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child())\n\u001b[0;32m   2047\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   2048\u001b[0m         output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   2049\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2050\u001b[0m             context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   2051\u001b[0m                 call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   2052\u001b[0m                 func,\n\u001b[0;32m   2053\u001b[0m                 input_,\n\u001b[0;32m   2054\u001b[0m                 config,\n\u001b[0;32m   2055\u001b[0m                 run_manager,\n\u001b[0;32m   2056\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2057\u001b[0m             ),\n\u001b[0;32m   2058\u001b[0m         )\n\u001b[0;32m   2059\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2060\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    427\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\prompts\\base.py:190\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m--> 190\u001b[0m     inner_input_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_input_)\n",
      "File \u001b[1;32me:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\langchain_core\\prompts\\base.py:184\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    178\u001b[0m     example_key \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m    179\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m to be part of the string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    185\u001b[0m         create_message(message\u001b[38;5;241m=\u001b[39mmsg, error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mINVALID_PROMPT_INPUT)\n\u001b[0;32m    186\u001b[0m     )\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Input to ChatPromptTemplate is missing variables {'Chat_history'}.  Expected: ['Chat_history', 'input'] Received: ['chat_history', 'input']\\nNote: if you intended {Chat_history} to be part of the string and not a variable, please escape it with double curly braces like: '{{Chat_history}}'.\\nFor troubleshooting, visit: https://docs.langchain.com/oss/python/langchain/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "result2 = conversational_rag_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"\"}\n",
    ")\n",
    "\n",
    "print(f\"Q: \")\n",
    "print(f\"A: {result1['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e611b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragudemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
