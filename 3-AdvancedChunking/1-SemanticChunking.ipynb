{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae922b1",
   "metadata": {},
   "source": [
    "# Semantic Chunking\n",
    "\n",
    "- SemanticChunker is a document splitter that uses embedding similarity between sentences to decide chunk boundaries.\n",
    "\n",
    "- It ensures that each chunk is semantically coherent and not cut off mid-thought like traditional character/token splitters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2697a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4a5239",
   "metadata": {},
   "source": [
    "## Document segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cbfd31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is a framework for building applications with LLMs.\\nLangchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\\nYou can create chains, agents, memory, and retrievers.\\nThe Eiffel Tower is located in Paris.\\nFrance is a popular tourist destination.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"langchain_intro.txt\",\"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f43a7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\n",
    "    model_name_or_path=\"all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff3a73da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LangChain is a framework for building applications with LLMs.',\n",
       " 'Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.',\n",
       " 'You can create chains, agents, memory, and retrievers.',\n",
       " 'The Eiffel Tower is located in Paris.',\n",
       " 'France is a popular tourist destination.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into sentences\n",
    "\n",
    "sentences = [s.strip() for s in text.split(\"\\n\") if s.strip()]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd880259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02109222, -0.04472178,  0.01087076, ..., -0.01217802,\n",
       "         0.08605651,  0.02890729],\n",
       "       [-0.0341802 , -0.10210427,  0.00366989, ..., -0.01398786,\n",
       "         0.04454356,  0.00551362],\n",
       "       [-0.02442169, -0.05424953, -0.13623357, ...,  0.03656349,\n",
       "         0.07216296, -0.03104779],\n",
       "       [ 0.06605352,  0.03884848,  0.01661559, ...,  0.03093833,\n",
       "         0.07991003,  0.05157556],\n",
       "       [ 0.10403012, -0.03097695,  0.02524884, ...,  0.07805593,\n",
       "         0.01353772, -0.026849  ]], shape=(5, 384), dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embed each sentence\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e58204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize threshold parameter\n",
    "threshold = 0.7\n",
    "chunks = []\n",
    "\n",
    "current_chunk = [sentences[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd29e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic grouping based on threshold\n",
    "\n",
    "for i in range(1, len(sentences)):\n",
    "    sim = cosine_similarity(\n",
    "        [embeddings[i-1]],\n",
    "        [embeddings[i]]\n",
    "    )[0][0]\n",
    "\n",
    "    if sim >= threshold:\n",
    "        current_chunk.append(sentences[i])\n",
    "    else:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "        current_chunk = [sentences[i]]\n",
    "\n",
    "chunks.append(\" \".join(current_chunk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b6cbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic chunks: \n",
      "\n",
      "Chunk 1:\n",
      "LangChain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
      "\n",
      "Chunk 2:\n",
      "You can create chains, agents, memory, and retrievers.\n",
      "\n",
      "Chunk 3:\n",
      "The Eiffel Tower is located in Paris.\n",
      "\n",
      "Chunk 4:\n",
      "France is a popular tourist destination.\n"
     ]
    }
   ],
   "source": [
    "print(\"Semantic chunks: \")\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"\\nChunk {idx+1}:\\n{chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7137f8",
   "metadata": {},
   "source": [
    "# RAG with modular coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d3fdc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Babu\\ragudemy\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_classic.schema import Document\n",
    "from langchain_classic.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_classic.schema.runnable import RunnableLambda, RunnableMap\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d43b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c718df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is a framework for building applications with LLMs.\\nLangchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\\nYou can create chains, agents, memory, and retrievers.\\nThe Eiffel Tower is located in Paris.\\nFrance is a popular tourist destination.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"langchain_intro.txt\",\"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9783314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom semantic chunker with threshold\n",
    "\n",
    "class ThresholdSemanticChunker:\n",
    "    def __init__(self,\n",
    "                 model_name: str = \"all-MiniLM-L6-v2\",\n",
    "                 threshold:float=0.7):\n",
    "        self.threshold = threshold\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def split(self, text: str):\n",
    "        sentences = [s.strip() for s in text.split(\"\\n\") if s.strip()]\n",
    "        embeddings = self.model.encode(sentences)\n",
    "\n",
    "        chunks = []\n",
    "        current_chunk = [sentences[0]]\n",
    "\n",
    "        for i in range(1, len(sentences)):\n",
    "            sim = cosine_similarity(\n",
    "                [embeddings[i-1]],\n",
    "                [embeddings[i]]\n",
    "            )[0][0]\n",
    "            if sim >= self.threshold:\n",
    "                current_chunk.append(sentences[i])\n",
    "            else:\n",
    "                chunks.append(\" \".join(current_chunk))\n",
    "                current_chunk = [sentences[i]]\n",
    "\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "        return chunks\n",
    "\n",
    "    def split_documents(self, docs):\n",
    "        results = []\n",
    "        for doc in docs:\n",
    "            for chunk in self.split(doc.page_content):\n",
    "                results.append(Document(page_content=chunk,\n",
    "                                        metadata=doc.metadata)\n",
    "                )\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "445aef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = ThresholdSemanticChunker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "585ae14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunker.split_documents([Document(page_content=text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a30704e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='LangChain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.'),\n",
       " Document(metadata={}, page_content='You can create chains, agents, memory, and retrievers.'),\n",
       " Document(metadata={}, page_content='The Eiffel Tower is located in Paris.'),\n",
       " Document(metadata={}, page_content='France is a popular tourist destination.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "248718bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vector store\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunks,\n",
    "                     embeddings\n",
    "                     )\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdc6306e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based on the following context\\n\\n{context}\\n\\nQuestion: {question}\\n')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt template\n",
    "\n",
    "template = \"\"\"Answer the question based on the following context\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0ec2565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM\n",
    "\n",
    "llm = init_chat_model(model=\"groq:llama-3.1-8b-instant\",\n",
    "                      temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebee3b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    RunnableMap(\n",
    "        {\n",
    "        \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "        \"question\": lambda x: x['question'],\n",
    "    }\n",
    ")\n",
    "| prompt\n",
    "| llm\n",
    "| StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f345a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The purpose of LangChain is to build applications with Large Language Models (LLMs) by providing modular abstractions to combine LLMs with tools like OpenAI and Pinecone.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {\"question\": \"What is the purpose of langchain? Explain in brief\"}\n",
    "result = rag_chain.invoke(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0fcac8",
   "metadata": {},
   "source": [
    "# Semantic chunker with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42944cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "016d6aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the models\n",
    "loader = TextLoader(\"langchain_intro.txt\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a4d003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize embedding model\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30a41275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create semantic chunker\n",
    "chunker = SemanticChunker(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e488a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the documents\n",
    "chunks= chunker.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff2d1fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " chunk 1: \n",
      " LangChain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
      "\n",
      " chunk 2: \n",
      " You can create chains, agents, memory, and retrievers. The Eiffel Tower is located in Paris. France is a popular tourist destination.\n"
     ]
    }
   ],
   "source": [
    "#print result\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n chunk {i+1}: \\n {chunk.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ea754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c28dcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "347e42c1",
   "metadata": {},
   "source": [
    "### Alternativs: to check with all sentences, not just adjacent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f233ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"\n",
    "The old lighthouse on the cliff blinked twice before going completely dark for the first time in seventy years.\n",
    "Electric cars rarely match their advertised range when driven across steep mountain roads.\n",
    "A famous violinist once claimed that silence between notes carries more emotion than the music itself.\n",
    "Deep-sea creatures often rely on bioluminescence to attract prey in absolute darkness.\n",
    "Modern CPUs internally reorder instructions to maximize throughput without breaking program semantics.\n",
    "Some people collect postcards because they feel like tiny frozen memories of distant worlds.\n",
    "In deserts, temperature drops so sharply at night that metal surfaces can form thin layers of frost.\n",
    "Quantum entanglement still feels like magic even to researchers who study it daily.\n",
    "Tourists in Norway often underestimate how quickly the weather can switch from sunny to stormy.\n",
    "The flavor of coffee changes noticeably depending on the altitude at which beans are grown.\n",
    "Ancient libraries used clay tablets long before the invention of paper or parchment.\n",
    "A dog’s ability to understand human pointing gestures is surprisingly unique among animals.\n",
    "Many classic video games used palette swapping to give characters multiple color variations.\n",
    "The number of satellites in low-Earth orbit has increased dramatically in the last five years.\n",
    "High-precision robots can assemble mechanical watches faster than most skilled artisans.\n",
    "A single poorly optimized SQL query can slow down an entire microservice ecosystem.\n",
    "Researchers found that bees can solve simple arithmetic tasks under controlled experiments.\n",
    "People in crowded cities often walk faster without realizing it.\n",
    "Old sailing ships measured speed using a weighted rope with knots tied at fixed intervals.\n",
    "Not all volcanic eruptions are explosive; some create slow-moving rivers of molten rock.\n",
    "The earliest train stations were designed more like luxury hotels than transportation hubs.\n",
    "Coral reefs act as natural breakwaters, reducing the energy of waves before they reach shore.\n",
    "Some languages, like Finnish, can express complex ideas using extremely long compound words.\n",
    "A perfectly ripe mango has a distinct fruity aroma that can be recognized even from a distance.\n",
    "Even simple board games can become mathematically complex when analyzed as decision trees.\n",
    "Meteor showers occur when Earth passes through clouds of debris left by ancient comets.\n",
    "Most modern keyboards are designed with a slight tilt to minimize wrist strain.\n",
    "The shape of a bird’s wings reveals a lot about its typical flight speed and maneuverability.\n",
    "Shipping containers revolutionized global trade more than any digital innovation of the last century.\n",
    "A classical hologram encodes information in the interference pattern of light waves.\n",
    "Children often learn new languages faster because they rely less on translation.\n",
    "The taste of chocolate can vary dramatically depending on its tempering process.\n",
    "Tree rings preserve a readable history of droughts, volcanic activity, and seasonal cycles.\n",
    "Some historians believe that early maps exaggerated sea monsters to discourage exploration.\n",
    "The blue tint in some lakes comes from sunlight scattering off very fine glacial sediments.\n",
    "Ancient astronomers predicted eclipses long before they understood why they occurred.\n",
    "A single strong magnet can erase data from old magnetic tape recordings.\n",
    "Astronauts often describe spacewalks as both peaceful and terrifying.\n",
    "Chess engines evaluate millions of board positions per second to choose the best move.\n",
    "The pattern on a giraffe’s skin is unique, much like a human fingerprint.\n",
    "Certain mushrooms glow faintly at night due to natural bioluminescent chemicals.\n",
    "Urban planners increasingly use digital twins to simulate city traffic flows.\n",
    "Rainbows always appear opposite to the position of the sun.\n",
    "Old manuscripts sometimes contain hidden notes written in lemon juice, revealed by heat.\n",
    "Ant colonies collectively make decisions faster than many human committees.\n",
    "Crystal radios can operate without any external power source apart from received waves.\n",
    "Fresh snow absorbs sound, making winter nights unusually quiet.\n",
    "3D printers can manufacture complex shapes that would be impossible to carve by hand.\n",
    "Some species of turtles can breathe through their skin in the water during hibernation.\n",
    "A well-designed user interface can make a complex system feel intuitive instantly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef50423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences before chunking: 50\n",
      "\n",
      "Total semantic chunks: 47\n",
      "\n",
      "Chunk 1:\n",
      "The old lighthouse on the cliff blinked twice before going completely dark for the first time in seventy years.\n",
      "\n",
      "Chunk 2:\n",
      "Electric cars rarely match their advertised range when driven across steep mountain roads.\n",
      "\n",
      "Chunk 3:\n",
      "A famous violinist once claimed that silence between notes carries more emotion than the music itself.\n",
      "\n",
      "Chunk 4:\n",
      "Deep-sea creatures often rely on bioluminescence to attract prey in absolute darkness. Certain mushrooms glow faintly at night due to natural bioluminescent chemicals.\n",
      "\n",
      "Chunk 5:\n",
      "Modern CPUs internally reorder instructions to maximize throughput without breaking program semantics.\n",
      "\n",
      "Chunk 6:\n",
      "Some people collect postcards because they feel like tiny frozen memories of distant worlds.\n",
      "\n",
      "Chunk 7:\n",
      "In deserts, temperature drops so sharply at night that metal surfaces can form thin layers of frost.\n",
      "\n",
      "Chunk 8:\n",
      "Quantum entanglement still feels like magic even to researchers who study it daily.\n",
      "\n",
      "Chunk 9:\n",
      "Tourists in Norway often underestimate how quickly the weather can switch from sunny to stormy.\n",
      "\n",
      "Chunk 10:\n",
      "The flavor of coffee changes noticeably depending on the altitude at which beans are grown.\n",
      "\n",
      "Chunk 11:\n",
      "Ancient libraries used clay tablets long before the invention of paper or parchment.\n",
      "\n",
      "Chunk 12:\n",
      "A dog’s ability to understand human pointing gestures is surprisingly unique among animals.\n",
      "\n",
      "Chunk 13:\n",
      "Many classic video games used palette swapping to give characters multiple color variations.\n",
      "\n",
      "Chunk 14:\n",
      "The number of satellites in low-Earth orbit has increased dramatically in the last five years.\n",
      "\n",
      "Chunk 15:\n",
      "High-precision robots can assemble mechanical watches faster than most skilled artisans.\n",
      "\n",
      "Chunk 16:\n",
      "A single poorly optimized SQL query can slow down an entire microservice ecosystem.\n",
      "\n",
      "Chunk 17:\n",
      "Researchers found that bees can solve simple arithmetic tasks under controlled experiments. Ant colonies collectively make decisions faster than many human committees.\n",
      "\n",
      "Chunk 18:\n",
      "People in crowded cities often walk faster without realizing it.\n",
      "\n",
      "Chunk 19:\n",
      "Old sailing ships measured speed using a weighted rope with knots tied at fixed intervals.\n",
      "\n",
      "Chunk 20:\n",
      "Not all volcanic eruptions are explosive; some create slow-moving rivers of molten rock.\n",
      "\n",
      "Chunk 21:\n",
      "The earliest train stations were designed more like luxury hotels than transportation hubs.\n",
      "\n",
      "Chunk 22:\n",
      "Coral reefs act as natural breakwaters, reducing the energy of waves before they reach shore.\n",
      "\n",
      "Chunk 23:\n",
      "Some languages, like Finnish, can express complex ideas using extremely long compound words.\n",
      "\n",
      "Chunk 24:\n",
      "A perfectly ripe mango has a distinct fruity aroma that can be recognized even from a distance.\n",
      "\n",
      "Chunk 25:\n",
      "Even simple board games can become mathematically complex when analyzed as decision trees. Chess engines evaluate millions of board positions per second to choose the best move.\n",
      "\n",
      "Chunk 26:\n",
      "Meteor showers occur when Earth passes through clouds of debris left by ancient comets.\n",
      "\n",
      "Chunk 27:\n",
      "Most modern keyboards are designed with a slight tilt to minimize wrist strain.\n",
      "\n",
      "Chunk 28:\n",
      "The shape of a bird’s wings reveals a lot about its typical flight speed and maneuverability.\n",
      "\n",
      "Chunk 29:\n",
      "Shipping containers revolutionized global trade more than any digital innovation of the last century.\n",
      "\n",
      "Chunk 30:\n",
      "A classical hologram encodes information in the interference pattern of light waves.\n",
      "\n",
      "Chunk 31:\n",
      "Children often learn new languages faster because they rely less on translation.\n",
      "\n",
      "Chunk 32:\n",
      "The taste of chocolate can vary dramatically depending on its tempering process.\n",
      "\n",
      "Chunk 33:\n",
      "Tree rings preserve a readable history of droughts, volcanic activity, and seasonal cycles.\n",
      "\n",
      "Chunk 34:\n",
      "Some historians believe that early maps exaggerated sea monsters to discourage exploration.\n",
      "\n",
      "Chunk 35:\n",
      "The blue tint in some lakes comes from sunlight scattering off very fine glacial sediments.\n",
      "\n",
      "Chunk 36:\n",
      "Ancient astronomers predicted eclipses long before they understood why they occurred.\n",
      "\n",
      "Chunk 37:\n",
      "A single strong magnet can erase data from old magnetic tape recordings.\n",
      "\n",
      "Chunk 38:\n",
      "Astronauts often describe spacewalks as both peaceful and terrifying.\n",
      "\n",
      "Chunk 39:\n",
      "The pattern on a giraffe’s skin is unique, much like a human fingerprint.\n",
      "\n",
      "Chunk 40:\n",
      "Urban planners increasingly use digital twins to simulate city traffic flows.\n",
      "\n",
      "Chunk 41:\n",
      "Rainbows always appear opposite to the position of the sun.\n",
      "\n",
      "Chunk 42:\n",
      "Old manuscripts sometimes contain hidden notes written in lemon juice, revealed by heat.\n",
      "\n",
      "Chunk 43:\n",
      "Crystal radios can operate without any external power source apart from received waves.\n",
      "\n",
      "Chunk 44:\n",
      "Fresh snow absorbs sound, making winter nights unusually quiet.\n",
      "\n",
      "Chunk 45:\n",
      "3D printers can manufacture complex shapes that would be impossible to carve by hand.\n",
      "\n",
      "Chunk 46:\n",
      "Some species of turtles can breathe through their skin in the water during hibernation.\n",
      "\n",
      "Chunk 47:\n",
      "A well-designed user interface can make a complex system feel intuitive instantly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# split into sentences\n",
    "sentences = [s.strip() for s in text2.split(\"\\n\") if s.strip()]\n",
    "print(f\"Total sentences before chunking: {len(sentences)}\")\n",
    "\n",
    "# get embeddings\n",
    "embeddings = model.encode(sentences)  # shape: (N, D)\n",
    "\n",
    "threshold = 0.4  # try 0.3–0.5 for typical sentence-transformer models\n",
    "chunks = []      # list of lists of sentence indices\n",
    "\n",
    "# start with first sentence in its own chunk\n",
    "chunks.append([0])\n",
    "\n",
    "for i in range(1, len(sentences)):\n",
    "    emb_i = embeddings[i].reshape(1, -1)\n",
    "\n",
    "    # compute similarity with ALL previous sentences (0..i-1)\n",
    "    prev_embs = embeddings[:i]\n",
    "    sims = cosine_similarity(emb_i, prev_embs)[0]  # shape: (i,)\n",
    "\n",
    "    # find most similar previous sentence\n",
    "    best_idx = int(np.argmax(sims))\n",
    "    best_sim = float(sims[best_idx])\n",
    "\n",
    "    if best_sim >= threshold:\n",
    "        # add to the chunk that contains best_idx\n",
    "        for ch in chunks:\n",
    "            if best_idx in ch:\n",
    "                ch.append(i)\n",
    "                break\n",
    "    else:\n",
    "        # start a new chunk\n",
    "        chunks.append([i])\n",
    "\n",
    "# convert index chunks to text chunks\n",
    "text_chunks = [\" \".join(sentences[j] for j in ch) for ch in chunks]\n",
    "\n",
    "print(f\"\\nTotal semantic chunks: {len(text_chunks)}\")\n",
    "for idx, chunk in enumerate(text_chunks, start=1):\n",
    "    print(f\"\\nChunk {idx}:\\n{chunk}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f458eca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragudemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
